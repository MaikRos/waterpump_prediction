{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>male 2012</th>\n",
       "      <th>female 2012</th>\n",
       "      <th>total 2012</th>\n",
       "      <th>male 2016</th>\n",
       "      <th>female 2016</th>\n",
       "      <th>total 2016</th>\n",
       "      <th>male 2017</th>\n",
       "      <th>female 2017</th>\n",
       "      <th>total 2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dodoma</td>\n",
       "      <td>1014974</td>\n",
       "      <td>1068614</td>\n",
       "      <td>2083588</td>\n",
       "      <td>1103105</td>\n",
       "      <td>1161402</td>\n",
       "      <td>2264508</td>\n",
       "      <td>1126308</td>\n",
       "      <td>1185832</td>\n",
       "      <td>2312141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arusha</td>\n",
       "      <td>821282</td>\n",
       "      <td>873028</td>\n",
       "      <td>1694310</td>\n",
       "      <td>916455</td>\n",
       "      <td>974197</td>\n",
       "      <td>1890652</td>\n",
       "      <td>941924</td>\n",
       "      <td>1001271</td>\n",
       "      <td>1943195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kilimanjaro</td>\n",
       "      <td>793140</td>\n",
       "      <td>846947</td>\n",
       "      <td>1640087</td>\n",
       "      <td>850669</td>\n",
       "      <td>908378</td>\n",
       "      <td>1759047</td>\n",
       "      <td>865691</td>\n",
       "      <td>924420</td>\n",
       "      <td>1790112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tanga</td>\n",
       "      <td>992347</td>\n",
       "      <td>1052858</td>\n",
       "      <td>2045205</td>\n",
       "      <td>1084963</td>\n",
       "      <td>1151122</td>\n",
       "      <td>2236086</td>\n",
       "      <td>1109438</td>\n",
       "      <td>1177089</td>\n",
       "      <td>2286527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>morogoro</td>\n",
       "      <td>1093302</td>\n",
       "      <td>1125190</td>\n",
       "      <td>2218492</td>\n",
       "      <td>1201198</td>\n",
       "      <td>1236233</td>\n",
       "      <td>2437431</td>\n",
       "      <td>1229796</td>\n",
       "      <td>1265665</td>\n",
       "      <td>2495462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        region  male 2012  female 2012  total 2012  male 2016  female 2016  \\\n",
       "0       dodoma    1014974      1068614     2083588    1103105      1161402   \n",
       "1       arusha     821282       873028     1694310     916455       974197   \n",
       "2  kilimanjaro     793140       846947     1640087     850669       908378   \n",
       "3        tanga     992347      1052858     2045205    1084963      1151122   \n",
       "4     morogoro    1093302      1125190     2218492    1201198      1236233   \n",
       "\n",
       "   total 2016  male 2017  female 2017  total 2017  \n",
       "0     2264508    1126308      1185832     2312141  \n",
       "1     1890652     941924      1001271     1943195  \n",
       "2     1759047     865691       924420     1790112  \n",
       "3     2236086    1109438      1177089     2286527  \n",
       "4     2437431    1229796      1265665     2495462  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read census data and split them into district/town data\n",
    "\n",
    "# source: http://www.nbs.go.tz/nbstz/index.php/english/statistics-by-subject/population-and-housing-census/844-tanzania-total-population-by-district-regions-2016\n",
    "# modifications -   moved districts to seperate tab, \n",
    "#                   cut off any decimals, \n",
    "#                   string modifications for easy comparison to training data\n",
    "\n",
    "xlsx = pd.read_excel('./data/Tanzania_Total_Population_by_District-Regions-2016_2017.xlsx', sheet_name=['lga', 'district'])\n",
    "\n",
    "# extract the lga-tab data from the dictionary and change all items in the name column to lower case \n",
    "# to protect from random capital letters during comparison\n",
    "df_town, df_district = xlsx['lga'], xlsx['district']\n",
    "for item in [df_town, df_district]:\n",
    "    item['name'] = item.name.apply(lambda x: x.lower()) \\\n",
    "                            .map(lambda x: x.strip())\n",
    "    #item['name'] = item['name']\n",
    "\n",
    "df_town.rename(columns={'name': 'lga'}, inplace=True)\n",
    "df_district.rename(columns={'name': 'region'}, inplace=True)\n",
    "df_district.head()\n",
    "#print(df_district.loc[df_district['name'] == 'iringa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>region</th>\n",
       "      <th>lga</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quantity</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50785</th>\n",
       "      <td>dmdd</td>\n",
       "      <td>1996</td>\n",
       "      <td>dmdd</td>\n",
       "      <td>35.290799</td>\n",
       "      <td>-4.059696</td>\n",
       "      <td>manyara</td>\n",
       "      <td>mbulu</td>\n",
       "      <td>2012</td>\n",
       "      <td>other</td>\n",
       "      <td>parastatal</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>surface</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51630</th>\n",
       "      <td>government of tanzania</td>\n",
       "      <td>1569</td>\n",
       "      <td>dwe</td>\n",
       "      <td>36.656709</td>\n",
       "      <td>-3.309214</td>\n",
       "      <td>arusha</td>\n",
       "      <td>arusha</td>\n",
       "      <td>2000</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17168</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.767863</td>\n",
       "      <td>-5.004344</td>\n",
       "      <td>singida</td>\n",
       "      <td>singida</td>\n",
       "      <td>2010</td>\n",
       "      <td>other</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>surface</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45559</th>\n",
       "      <td>finn water</td>\n",
       "      <td>267</td>\n",
       "      <td>finn water</td>\n",
       "      <td>38.058046</td>\n",
       "      <td>-9.418672</td>\n",
       "      <td>lindi</td>\n",
       "      <td>liwale</td>\n",
       "      <td>1987</td>\n",
       "      <td>other</td>\n",
       "      <td>user-group</td>\n",
       "      <td>unknown</td>\n",
       "      <td>soft</td>\n",
       "      <td>dry</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49871</th>\n",
       "      <td>bruder</td>\n",
       "      <td>1260</td>\n",
       "      <td>bruder</td>\n",
       "      <td>35.006123</td>\n",
       "      <td>-10.950412</td>\n",
       "      <td>ruvuma</td>\n",
       "      <td>mbinga</td>\n",
       "      <td>2000</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>monthly</td>\n",
       "      <td>soft</td>\n",
       "      <td>enough</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       funder  gps_height   installer  longitude   latitude  \\\n",
       "id                                                                            \n",
       "50785                    dmdd        1996        dmdd  35.290799  -4.059696   \n",
       "51630  government of tanzania        1569         dwe  36.656709  -3.309214   \n",
       "17168                     NaN        1567         NaN  34.767863  -5.004344   \n",
       "45559              finn water         267  finn water  38.058046  -9.418672   \n",
       "49871                  bruder        1260      bruder  35.006123 -10.950412   \n",
       "\n",
       "        region      lga  construction_year extraction_type_class  \\\n",
       "id                                                                 \n",
       "50785  manyara    mbulu               2012                 other   \n",
       "51630   arusha   arusha               2000               gravity   \n",
       "17168  singida  singida               2010                 other   \n",
       "45559    lindi   liwale               1987                 other   \n",
       "49871   ruvuma   mbinga               2000               gravity   \n",
       "\n",
       "      management_group payment_type water_quality      quantity source_class  \\\n",
       "id                                                                             \n",
       "50785       parastatal    never pay          soft      seasonal      surface   \n",
       "51630       user-group    never pay          soft  insufficient  groundwater   \n",
       "17168       user-group    never pay          soft  insufficient      surface   \n",
       "45559       user-group      unknown          soft           dry  groundwater   \n",
       "49871       user-group      monthly          soft        enough  groundwater   \n",
       "\n",
       "      waterpoint_type_group  \n",
       "id                           \n",
       "50785                 other  \n",
       "51630    communal standpipe  \n",
       "17168                 other  \n",
       "45559                 other  \n",
       "49871    communal standpipe  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = ['id','gps_height','region', 'lga', 'latitude', 'longitude', 'construction_year', 'funder', 'installer', 'extraction_type_class','management_group','payment_type','water_quality','quantity','source_class', 'waterpoint_type_group']\n",
    "\n",
    "\n",
    "training_data = pd.read_csv('training_data.csv', skipinitialspace=True, usecols=fields, index_col=0)\n",
    "test_data = pd.read_csv('test_data.csv', skipinitialspace=True, usecols=fields, index_col=0)\n",
    "\n",
    "def replace_region_strings(df):\n",
    "    df[['region','lga', 'funder', 'installer']] = df[['region','lga', 'funder', 'installer']].apply(lambda x: x.str.lower()) \\\n",
    "                                                                 .apply(lambda x: x.str.replace(' urban','') \\\n",
    "                                                                 .str.replace(' rural', ''))\n",
    "    return df\n",
    "\n",
    "training_data = replace_region_strings(training_data)\n",
    "test_data = replace_region_strings(test_data)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are a lot of 0 values in ['longitude'] - we will replace these together with the corresponding latitudes\n",
    "# via the mean of all wells in the corresponding lga \n",
    "# (the smallest area provided by the data set - the most accurate)\n",
    "\n",
    "#calculate mean lat/lon for each lga\n",
    "def calculate_mean(df, name_col, num_col):\n",
    "    mean_dict = {}\n",
    "    df[num_col].replace(0, np.NaN, inplace = True)\n",
    "    for item in df[name_col].unique().tolist():\n",
    "        mean_dict[item] = np.NaN\n",
    "        mean_dict[item] = df.loc[df[name_col] == item,num_col].mean()\n",
    "    return mean_dict\n",
    "\n",
    "\n",
    "longitude = calculate_mean(training_data, 'lga', 'longitude')\n",
    "latitude = calculate_mean(training_data, 'lga', 'latitude')\n",
    "gps = calculate_mean(training_data, 'lga', 'gps_height')\n",
    "constr_year = calculate_mean(training_data, 'lga', 'construction_year')\n",
    "\n",
    "df = pd.DataFrame([latitude, longitude, gps, constr_year]).T\n",
    "df.columns = ['latitude', 'longitude', 'gps_height', 'construction_year']\n",
    "for item in ['gps_height', 'construction_year']:\n",
    "    df[item] = df.loc[:, item].fillna(df[item].mean()) # inaccurate!\n",
    "    \n",
    "# for all those regions where no geodata was collected, we replace them with the mean values of all regions\n",
    "# we also save the data to csv in case we need to share them\n",
    "conditions = (df['latitude'].isnull()) | (df['longitude'].isnull())\n",
    "df.loc[conditions, ['latitude', 'longitude']] = [df['latitude'].mean(), df['longitude'].mean()]\n",
    "df.to_csv('./data/mean_lon_lat_height.csv', na_rep='NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is also done for the district in case all wells in an lga dont have lat/lon values\n",
    "distr_longitude = calculate_mean(training_data, 'region', 'longitude')\n",
    "distr_latitude = calculate_mean(training_data, 'region', 'latitude')\n",
    "distr_gps = calculate_mean(training_data, 'region', 'gps_height')\n",
    "constr_year = calculate_mean(training_data, 'lga', 'construction_year')\n",
    "\n",
    "# create a df from the district values and save it to csv\n",
    "df_d = pd.DataFrame([distr_latitude, distr_longitude, distr_gps]).T\n",
    "df_d.columns = ['d_latitude', 'd_longitude', 'd_gps_height']\n",
    "df_d['d_gps_height'] = df_d.loc[:, 'd_gps_height'].fillna(df_d['d_gps_height'].mean()) # inaccurate!\n",
    "df_d.to_csv('./data/mean_lon_lat_height_district.csv', na_rep='NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we test if any value in the current df is null in order to create a function\n",
    "# to replace it -> no null values :) \n",
    "# df1 = df[df.isnull().any(axis=1)]\n",
    "# df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "901.959465198053"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what is the actual mean of gps_height \n",
    "df['gps_height'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we replace the null values in gps and construction year with their respective column means\n",
    "# this might be inaccurate since tanzania probably contains a wide range of gps heights \n",
    "# -> might be better to replace with district/lga mean/median gps height - same for construction year\n",
    "# construction year could be transformed to \"years/time of operation\" \n",
    "\n",
    "def replace_null_lga(df, mean_df):\n",
    "    'replaces the null values with the mean of the respective lga'\n",
    "    for lga in mean_df.index:\n",
    "        for item in ['longitude', 'latitude']:\n",
    "            df.loc[(df['lga'] == lga) & (df[item].isnull()), item] = mean_df.loc[lga, item]\n",
    "    return df\n",
    "\n",
    "\n",
    "training_data_cleaned = replace_null_lga(training_data, df)\n",
    "test_data_cleaned = replace_null_lga(test_data, df)\n",
    "\n",
    "for item in ['gps_height', 'construction_year']:\n",
    "    condition = training_data_cleaned[item].isnull()\n",
    "    condition_test = test_data_cleaned[item].isnull()\n",
    "    training_data_cleaned.loc[condition, item] = round(df[item].mean(),0)\n",
    "    training_data_cleaned[item] = training_data_cleaned[item].astype('int')\n",
    "    test_data_cleaned.loc[condition_test, item] = round(df[item].mean(),0)\n",
    "    test_data_cleaned[item] = test_data_cleaned[item].astype('int')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# here we create a dictionary in order to add the region / town specific population to the df\n",
    "# the population likely to use a well should have enourmous impact on their functionality -> lots of people, lots of damage\n",
    "# this is probably also dependent on the amount of functioning wells in the region -> maybe calculate \n",
    "\n",
    "def swaptionary(df, name, year):\n",
    "    swap_dict = dict(zip(df[name], df[year]))\n",
    "    return swap_dict\n",
    "\n",
    "for df, name, col in zip([df_district, df_town],['region_pop', 'lga_pop'], ['region', 'lga']):\n",
    "    training_data_cleaned[name] = training_data_cleaned[col].map(swaptionary(df, col, 'total 2012'))\n",
    "#training_data_cleaned['lga_pop'] = training_data_cleaned['lga'].map(swaptionary(df_town, 'lga', 'total 2012'))\n",
    "#print(swaptionary(df_district, 'region', 'total 2012'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we change the latitude/longitude column into a shapely point in order to calculate \n",
    "# the distance to other wells properly\n",
    "\n",
    "def create_points_from_lon_lat(lat, lon):\n",
    "    from shapely.geometry import Point\n",
    "    geometry = [Point(xy) for xy in zip(lat, lon)]\n",
    "    return geometry\n",
    "\n",
    "for item in [training_data_cleaned, test_data_cleaned]:\n",
    "    item['geometry'] = create_points_from_lon_lat(item['latitude'], item['longitude'])\n",
    "#training_data_cleaned = training_data_cleaned.drop(['latitude', 'longitude'], axis='columns')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# with the points we want to estimate the number of wells in differing proximities (1, 2, 5, 10 km for example)\n",
    "# in order to accomplish that task we need to define a coordinate reference system (crs) as well as a model for gravity, \n",
    "# coordinates and the shape of the earth - the most current is the so called WGS84 or EPSG:4326 (world geode system 1984)\n",
    "import pyproj as proj\n",
    "\n",
    "crs_wgs = proj.Proj(init='epsg:4326') # WGS84 geode system \n",
    "crs_country = proj.Proj(init='epsg:1285') #<- crs for tanzania - 15 m accuracy\n",
    "\n",
    "#'epsg:21037' <-  CRS for Tanzania + kenya - Accuracy 35.0 m - that means 1 unit is 35 m ?\n",
    "\n",
    "# then cast your geographic coordinate pair to the projected system\n",
    "x, y = proj.transform(crs_wgs, crs_country, input_lon, input_lat)\n",
    "\n",
    "point_1 = geometry.Point(x_1, y_1)\n",
    "point_2 = geometry.Point(x_2, y_2)\n",
    "\n",
    "# create your circle buffer from one of the points\n",
    "distance = 1000 # units -> 35 km?\n",
    "circle_buffer = point_1.buffer(distance)\n",
    "\n",
    "# and you can then check if the other point lies within\n",
    "if point_2.within(circle_buffer):\n",
    "    print('point 2 is within the distance buffer of point 1')\n",
    "# or similarly\n",
    "if circle_buffer.contains(point_2):\n",
    "    print('circle buffer contains point 2')\n",
    "\n",
    "# but a simpler method is to simply check the distance\n",
    "if point_1.distance(point_2) < distance:\n",
    "    print('point 1 is within the distance of point 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the next step we evaluate whether the people funding the operation are also the ones who installed the pumps \n",
    "# in theory if these are equal that should mean more commitment to keep the wells flush\n",
    "#print(test_data_cleaned['funder'])\n",
    "for item in [training_data_cleaned, test_data_cleaned]:\n",
    "    item['funder'] = item['funder'].fillna('unknown')\n",
    "    item['installer'] = item['installer'].fillna('unknown')\n",
    "    item['funder_is_installer'] = item['funder'] == item['installer']\n",
    "    item = item.replace({'funder': {0:'unknown'}, 'installer':{0:'unknown'} })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to train the model properly we make sure that there are no null values in the data \n",
    "# and drop the columns not needed for modeling\n",
    "training_data_cleaned = training_data_cleaned.drop(['geometry'], axis=1) # 'funder', 'installer'\n",
    "test_data_cleaned = test_data_cleaned.drop(['geometry'], axis=1)\n",
    "\n",
    "#print(training_data_cleaned[training_data_cleaned.isnull().any(axis=1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "features = ['funder',\n",
    "            'installer',\n",
    "            'region', \n",
    "            'lga', \n",
    "            'extraction_type_class', \n",
    "            'management_group', \n",
    "            'payment_type', \n",
    "            'water_quality',\n",
    "            'quantity', \n",
    "            'source_class', \n",
    "            'waterpoint_type_group',\n",
    "            'funder_is_installer' \n",
    "           ]\n",
    "#print(training_data_cleaned.head())\n",
    "for item in features:\n",
    "    training_data_cleaned[item] = encoder.fit_transform(training_data_cleaned[item])\n",
    "    test_data_cleaned[item] = encoder.fit_transform(test_data_cleaned[item])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "training_set_labels = pd.read_csv('training_set_labels.csv', index_col=0)\n",
    "df = pd.merge(training_data_cleaned, training_set_labels, left_index=True, right_index=True)\n",
    "\n",
    "df = df.replace({'status_group': {'functional': 1, 'functional needs repair': 0, 'non functional': -1} })\n",
    "\n",
    "y = df.status_group\n",
    "x = df.drop(['status_group', 'region_pop', 'lga_pop'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=291)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000, \n",
    "                             min_samples_split=6,\n",
    "                             criterion='gini', \n",
    "                             max_features='auto',\n",
    "                             oob_score=True,\n",
    "                             random_state=291,\n",
    "                             n_jobs=-1\n",
    "                            )\n",
    "#clf = XGBClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.73%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x, y)\n",
    "y_pred = clf.predict(test_data_cleaned)\n",
    "\n",
    "test_data_cleaned['prediction'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = test_data_cleaned[['prediction']]\n",
    "df_submit = df_submit.replace({'prediction': {1:'functional', 0:'functional needs repair', -1:'non functional'} })\n",
    "df_submit.head()\n",
    "df_submit.to_csv('submit180117-3.csv', header=['status_group'], index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA of numerical values! \n",
    "# year since creation -> fill missing values with mean \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
